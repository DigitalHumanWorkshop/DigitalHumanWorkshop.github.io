
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
  <!-- SITE TITTLE -->
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Home | Digital Human Workshop at NeurIPS 2023</title>
  
  <!-- PLUGINS CSS STYLE -->
  <link href="./res/jquery-ui.min.css" rel="stylesheet">
  <!-- Bootstrap -->
  <link href="./res/bootstrap.min.css" rel="stylesheet">
  <!-- Font Awesome -->
  <link href="./res/font-awesome.min.css" rel="stylesheet">
  <!-- Owl Carousel -->
  <link href="./res/slick.css" rel="stylesheet">
  <link href="./res/slick-theme.css" rel="stylesheet">
  <!-- Fancy Box -->
  <link href="./res/jquery.fancybox.pack.css" rel="stylesheet">
  <link href="./res/nice-select.css" rel="stylesheet">
  <link href="./res/bootstrap-slider.min.css" rel="stylesheet">
  <!-- CUSTOM CSS -->
  <link href="./res/style.css" rel="stylesheet">
  
  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
 <style type="text/css">
  .left,
  .right {
    float: left;
    width: 50%;
    padding-left: 0px;
  }
  .left { padding-left: 20px; }
</style> 
  </head>
  
  <body class="body-wrapper" data-new-gr-c-s-check-loaded="14.997.0" data-gr-ext-installed="">
      <section>
        <div class="container">
          <div class="row">
            <div class="col-md-12">
              <nav class="navbar navbar-expand-lg  navigation"> <a class="navbar-brand" href="https://nips.cc/Conferences/2023/Board"> <img src="./asset/NIPS23.jpg" alt="" width="85px"> </a>
                <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"> <span class="navbar-toggler-icon"></span> </button>
                <div class="collapse navbar-collapse" id="navbarSupportedContent">
                  <ul class="navbar-nav ml-auto main-nav">
                    <li class="nav-item active"> <a class="nav-link" href="#overview">Home</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#call">Calls</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#speakers">Speakers</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#challenge">Challenge</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#organizers">Organizer</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#paper">Papers</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#sponsors">Sponsors</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#committee">Committee</a> </li>
                    <li class="nav-item"> <a class="nav-link " href="#previous">Previous</a> </li>
                  </ul>
                  
                </div>
              </nav>
            </div>
          </div>
        </div>
      </section>
  
  
  <!--==========================================
  =            Overview Section            =
  ===========================================-->
  
  <section class="popular-deals section bg-gray"> 
    <!-- Container Start -->
    <div class="container">
      <div class="row">
        <div class="col-md-12"> 
          <!-- Section title -->
          <div class="section-title">
            <h1>1st International Workshop on <br>High-fidelity Digital Human
              Reconstruction and Animation</h1>
      <br>
      <h4>Workshop at Neural Information Processing Systems 2023</h4>
      <br><br>
            <h2 id="overivew">Overview</h2>
          </div>
          Digital humans are important research topics with many applications, such as
          gaming, virtual reality, and the metaverse. In the traditional pipeline, manual labor
          is heavily involved in digital human creation and animation. To facilitate research
          in this direction, we plan to promote the use of machine learning methods for digital
          humans in this competition, in pursuit of automatic and high-fidelity reconstruction
          and animation. We focus on three challenging machine learning problems for digital
          human, i.e., self-supervised learning, semi-supervised learning, and multi-modal
          learning. Self-supervised learning and semi-supervised learning are important for
          digital human reconstruction, where ground-truth data is expensive and scarce
          for large-scale supervised training. Multi-modal learning is indispensable for
          constructing a vivid digital human, e.g., driving a digital human with audio. We
          design four tracks for participants to get easily involved, and provide the baseline
          models for these sub-tasks and expect the participants to develop novel solutions.
          This competition is also naturally related to computer vision, which is closely
          related to the NeurIPS community. Under the topic of digital human, the latest
          developments in machine learning and computer vision can be put together.
    <!-- <br><br>
    <strong><font color="#FF0000">Important:</font> The submission deadline has been extended to 15th Nov 2022 (AoE).</strong>
    (<a href="https://cmt3.research.microsoft.com/PracticalDL2023/" style="color:blue;">Submission Site</a>)
    <br> -->
      </div>
      </div>
    </div>
  </section>
  

    <!--==========================================
  =            Call for Papers Section            =
  ===========================================-->
  
  <section class="section"> 
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="call">Call for Papers</h2>
          </div>
<!-- 
          Recently, the success of deep learning in AI has attracted great attention from academia and industry. However, research shows that the performance of models in the wild is far from practical due to the lack of efficiency and robustness towards open-world data and scenarios. We welcome research contributions related to the following (but not limited to) topics:<br>
    <ul style="margin-left: 40px">
    <li>Network quantization and binarization</li>
    <li>Adversarial attacking deep learning systems</li>
    <li>Neural architecture search (NAS)</li>
    <li>Robust architectures against adversarial attacks</li>
    <li>Hardware implementation and on-device deployment</li>
    <li>Benchmark for evaluating model robustness</li>
    <li>New methodologies and architectures for efficient and rubost deep learning</li>
    </ul>
    <strong>Submission Format</strong>: Submissions papers (.pdf format) must use the AAAI Article Template and be anonymized and follow AAAI 2023 author instructions. The workshop considers two types of submissions: (1) Long Paper: Papers are limited to 7 pages excluding references; (2) Extended Abstract: Papers are limited to 4 pages including references.
        <br>
        The excellent papers will be invited to the <a href="https://www.journals.elsevier.com/pattern-recognition/call-for-papers/practical-deep-learning-in-the-wild" style="color:blue;">Special Issue</a>  of Pattern Recognition journal for publication consideration.
        <br>
        <strong>Submission Site</strong>: <a href="https://cmt3.research.microsoft.com/PracticalDL2023/" style="color:blue;">https://cmt3.research.microsoft.com/PracticalDL2023/</a> 
        <br>
        <strong>Submission Due</strong>: 15th Nov, 2022 (AoE)  -->

        </div>
      </div>
    </div>
  </section>


  <!--===========================================
  =            Workshop Arrangement            =
  ============================================-->
  
  <section class="section">
    <div class="container">
      <div class="row">
        <div class="col-md-12">
          <div class="section-title">
            <h2 id="dates">Workshop Schedule</h2>
          </div>
            <!-- <p align="center">
                <img src="./res/schedule2023.png" width="90%">
            </p> -->
        </div>
      </div>
    </div>
  </section>


<!--==========================================
=            Speakers Section            =
===========================================-->
<section class="popular-deals section bg-gray"> 
  <!-- Container Start -->
  <div class="container">
    <div class="row">
      <div class="col-12"> 
        <!-- Section title -->
        <div class="section-title">
          <h2 id="speakers">Keynote Speakers</h2>
        </div>
        <!-- <div class="card-deck"> 


          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/adam.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://generativevision.mpi-inf.mpg.de/">Adam Kortylewski</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Max-Planck-Institut f√ºr Informatik<br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/priyadarshini.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://seas.yale.edu/faculty-research/faculty-directory/priya-panda">Priyadarshini Panda</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Yale University<br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/florian.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://floriantramer.com/">Florian Tramer</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>ETH Z√ºrich<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
 
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/neil.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://people.duke.edu/~zg70/">Neil Gong</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Duke University<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/markus.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://www.apax.com/people/our-team/markus-nagel/">Markus Nagel</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Qualcomm AI Research<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
                              
  </div>
  <br>
  
        <div class="card-deck"> 


          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/jie.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://sites.google.com/view/jie-zhang/home">Jie M. Zhang</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>King's College London</p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/vsehwag.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://vsehwag.github.io/">Vikash Sehwag</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Princeton University</p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>

          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/shouling.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://scholar.google.com/citations?user=5HoF_9oAAAAJ">Shouling Ji</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Zhejiang University</p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">

            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/bichen.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://scholar.google.com/citations?user=K3QJPdMAAAAJ&hl=en">Bichen Wu</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Meta</p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
                              
  </div> -->
  
      </div>
    </div>
  </div>
  <!-- Container End --> 
  
  </section>


  

    <!--==========================================
  =            Challenge Section            =
  ===========================================-->
  
  <section class="section"> 
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="challenge">Digital Human Challenge</h2>
          </div>
          <!-- Deep learning has achieved significant success in multimedia fields, however research in adversarial learning also shows that it is highly vulnerable to adversarial examples. We invite submissions on any aspect of adversarial machine learning in multimedia deep learning systems. -->
          The challenge is held jointly with the "1st International Workshop on High-fidelity Digital Human Reconstruction and Animation" at NeurIPS 2023.<br>
          <strong>Task 1: Self-Supervised Face Appearance Reconstruction</strong>
          <ul style="margin-left: 40px">
          <li>The objective of this task is to introduce self-supervised learning for face appearance reconstruction.
            Traditional photometric-based methods require capturing multi-view images under different lighting
            conditions to obtain high-quality facial appearance assets. However, this often requires the use of
            large devices like light-stages. In this competition, we encourage participants to calculate detailed
            digital face appearances from limited lighting and a small number of photos without relying on
            high-end equipment. Participants need to design a self-supervised learning framework to decompose
            detailed normal maps and a displacement map.</li>
          </ul>
          <strong>Task 2: Semi-supervised 3D Skull Reconstruction</strong>
          <ul style="margin-left: 40px">
          <li>Efficient, accurate, and robust algorithms for 3D skull reconstruction can play a significant role in
            achieving internal and external consistency in digital humans‚Äô parametric models (see Figure 2).
            In this task, we expect the cranial reconstruction algorithm to reconstruct the anatomical geometry
            of the skull based on the information provided by MRI, including but not limited to the precise
            geometry of the external surface of the face, the internal soft tissue structures of the face, and
            the characteristic points of the skull. This competition encourages participants to develop a semi-
            supervised learning-based cranial segmentation algorithm for MRI images using machine learning and
            deep learning techniques. The segmentation algorithm can fully exploit the information of unlabeled
            training samples based on a small number of labeled samples while improving the performance and
            generalization of the segmentation model. Ultimately, the high-quality segmentation results obtained
            on MRI will serve as the basis for 3D skull reconstruction.</li>
          </ul>
          <strong>Task 3: Multi-modal Learning for Audio-driven Talking Head Generation</strong>
          <ul style="margin-left: 40px">
          <li>In this task, we specifically focus on the ability to generate talking heads with realistic facial
            expressions and natural head poses that match the accompanying audio. By learning from both the
            audio and visual data, this task focuses on developing a multi-modal learning model for talking head
            generation. We further design the following two settings to motivate the participants to tackle this
            task with 2D and 3D methods, respectively.
            Single image setting: Participants are allowed to train their model with external data, and we will
            provide a single image for their models to animate.
            Video setting: Participants are not allowed to train their model with external data, while a two-minute
            training video is provided for training a personalized talking head model.
            The final output of both settings should be a talking head model that can be driven by any input audio.
            For the image setting, the synthesized talking head videos are expected to be lip-synchronized and
            with high fidelity. As for the video setting, the speakers should additionally have various natural
            poses during talking while preserving their identity.</li>
          </ul>
          <strong>Task 4: Multi-modal Learning for Audio-driven Co-speech Gesture Synthesis</strong>
          <ul style="margin-left: 40px">
          <li>Nonverbal behaviors, especially co-speech gestures, are vital for face-to-face communication. Studies
            have shown that gestures can help express intentions, convey emotions, and complement the informa-
            tion conveyed by speech. Recent research has demonstrated that machine learning-based approaches
            play an increasingly critical role in motion synthesis, which has become the primary method for
            co-speech gesture synthesis.
            In this task, individuals and teams are required to synthesize 3D talking gestures based on any given
            audio. The final output should be a 3D motion sequence that can drive a given 3D avatar. Generally,
            the synthesized gesture motions in this task are expected to be natural, difficult to distinguish from
            captured human gesture motions, and consistent with audio in terms of rhythm, semantics, and style.
            We encourage participants to propose novel ideas for synthesizing high-fidelity co-speech gestures.</li>
          </ul>

          <strong>Challenge Site</strong>: <a href="https://practical-dl.sensecore.cn/" style="color:blue;">https://practical-dl.sensecore.cn</a> 
          <br>
          <strong>Submission Due</strong>: 31th Dec, 2022 (AoE)
        </div>
      </div>
    </div>
  </section>

<!--==========================================
=            Organizers Section            =
===========================================-->

<section class="popular-deals section bg-gray"> 
  <!-- Container Start -->
  <div class="container">
    <div class="row">
      <div class="col-12"> 
        <!-- Section title -->
        <div class="section-title">
          <h2 id="organizers">Organizer</h2>
        </div>
        <!-- <div class="card-deck"> 

          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/haotong.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://htqin.github.io/">Haotong Qin</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Beihang University<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/ruihao.jpg" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://xhplus.github.io/">Ruihao Gong</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>SenseTime Research<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/jiakai.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://jiakaiwangcn.github.io/">Jiakai Wang</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Zhongguancun Laboratory<br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/siyuan.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://scholar.google.com/citations?user=Hon4nf0AAAAJ">Siyuan Liang</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Chinese Academy of Sciences<br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/zeyu.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://zysszy.github.io/">Zeyu Sun</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p><br>Zhongguancun Laboratory<br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
                              
  </div>
  <br>
  
        <div class="card-deck"> 

          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/aishan.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://liuaishan.github.io/">Aishan Liu</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Beihang University<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/wenbo.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="http://staff.ustc.edu.cn/~welbeckz/">Wenbo Zhou</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>University of Science and Technology of China<br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/shanghang.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://www.shanghangzhang.com/">Shanghang Zhang</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Peking University</p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">
            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/fisher.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://www.yf.io/">Fisher Yu</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>ETH Z√ºrich<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
          <div class="card">

            <div class="category-block">
              <table width="80%" border="0" align="center">
                <tbody align="center">
                  <tr height="200px">
                    <td><img src="./res/xianglong.png" alt="" class="rounded-circle" width="60%"></td>
                  </tr>
                  <tr height="30px">
                    <td><h5 class="text-center"><a href="https://xlliu-beihang.github.io/">Xianglong Liu</a></h5></td>
                  </tr>
                  <tr height="60px">
                    <td><p>Beihang University<br><br><br><br></p></td>
                  </tr>
                </tbody>
              </table>
            </div>
          </div>
                              
  </div>
   -->
      </div>
    </div>
  </div>
  <!-- Container End --> 
  </section>



    <!--==========================================
  =            Paper Submission Section            =
  ===========================================-->
  
  <!--  <section class="section"> 
    <div class="container">
      <div class="row">
        <div class="col-12">
          <div class="section-title">
            <h2 id="paper-submission">Paper Submission</h2>
          </div>
          <strong>Format</strong>: Submissions need to be anonymized and follow AAAI 2022 author instructions. The workshop considers two types of submissions: (1) Long Paper: Papers are limited to <strong>7</strong> pages excluding references; (2) Extended Abstract: Papers are limited to <strong>4</strong> pages including references.

    <br>
    <strong>Submission Server</strong>: <a href="https://cmt3.research.microsoft.com/">https://cmt3.research.microsoft.com/</a> .
    
  </div>
  </div>
  
-->
    <!-- br>
    <br> -->
    
    <section class="section"> 
      <div class="container">
        <div class="row">
          <div class="col-12">
          <div class="section-title">
            <h2 id="paper">Accepted Papers</h2>
          </div>

    <div class="container">
    <h2>Accepted Long Paper</h2>
    <div class="overview">
    <!-- <ul>
      <li><strong>Automatic Neural Network Pruning that Efficiently Preserves the Model Accuracy</strong> [<a href="https://practical-dl.github.io/2023/long_paper/1/CameraReady/1.pdf" target="">Paper</a>] [<a href="https://practical-dl.github.io/2023/long_paper/1/CameraReady/1_supplementary.zip" target="">Supp</a>] <br>
      Thibault Castells (Nota AI GmbH); Seul-Ki Yeom (Nota AI GmbH)*</li>

      <li><strong>HesScale: Scalable Computation of Hessian Diagonals</strong> [<a href="https://practical-dl.github.io/2023/long_paper/2/CameraReady/2.pdf" target="">Paper</a>]  <br>
      Mohamed Elsayed (University of Alberta)*; Rupam Mahmood (University of Alberta)</li>
      
      <li><strong>Contrastive View Design Strategies to Enhance Robustness to Domain Shifts in Downstream Object Detection</strong> [<a href="https://practical-dl.github.io/2023/long_paper/3/CameraReady/3.pdf" target="">Paper</a>] <br>
      Kyle R Buettner (University of Pittsburgh)*; Adriana Kovashka (University of Pittsburgh)</li>
      
      <li><strong>Model and Data Agreement for Learning with Noisy Labels</strong> [<a href="https://practical-dl.github.io/2023/long_paper/6/CameraReady/6.pdf" target="">Paper</a>] <br>
      Yuhang Zhang (Inspur Electronic Information Industry Co., Ltd.)*; Weihong Deng (Inspur); Xingchen Cui (Inspur Electronic Information Industry Co., Ltd.); Yunfeng Yin (Inspur); Hongzhi Shi (Inspur Electronic Information Industry Co., Ltd); Dongchao Wen (Inspur Electronic Information Industry Co., Ltd.)</li>

      <li><strong>Expeditious Saliency-guided Mix-up through Random Gradient Thresholding</strong>  [<a href="https://practical-dl.github.io/2023/long_paper/7/CameraReady/7.pdf" target="">Paper</a>] [<a href="https://practical-dl.github.io/2023/long_paper/7/CameraReady/7-supp.zip" target="">Supp</a>] <br>
      Long Minh Luu (International University - VNUHCM)*; Zeyi Huang (Carnegie Mellon University); Haohan Wang (University of Illinois Urbana-Champaign); Yong Jae Lee (University of Wisconsin-Madison); Eric Xing (MBZUAI, CMU, and Petuum Inc.)</li>

      <li><strong>Generalizability of Adversarial Robustness Under Distribution Shifts</strong> [<a href="https://practical-dl.github.io/2023/long_paper/9/CameraReady/9.pdf" target="">Paper</a>] [<a href="https://practical-dl.github.io/2023/long_paper/9/CameraReady/9-supp.zip" target="">Supp</a>]  <br>
      Kumail Alhamoud (KAUST)*; Hasan Abed Al Kader Hammoud (King Abdullah University of Science and Technology ); Motasem Alfarra (KAUST); Bernard Ghanem (KAUST)</li>
      
      <li><strong>Explanation-based Adversarial Detection with Noise Reduction</strong>  [<a href="https://practical-dl.github.io/2023/long_paper/14/CameraReady/14.pdf" target="">Paper</a>]  <br>
      Juntao Su (The George Washington University)*; Zhou Yang (The George Washington University); Zexin Ren (George Washingtong University); Fang Jin (George Washington University)</li>

      <li><strong>Efficient Fusion of Image Attributes: A New Approach to Visual Recognition</strong> [<a href="https://practical-dl.github.io/2023/long_paper/16/CameraReady/16.pdf" target="">Paper</a>]  <br>
      Dehao Yuan (University of Maryland)*; Minghui Liu (University of Maryland); Cornelia Fermuller (University of Maryland, College Park); Yiannis Aloimonos (University of Maryland, College Park)</li>

      <li><strong>Systematic Quantization of Vision Models based on MLPs</strong>  [<a href="https://practical-dl.github.io/2023/long_paper/17/CameraReady/17.pdf" target="">Paper</a>]  [<a href="https://practical-dl.github.io/2023/long_paper/17/CameraReady/17-supp.zip" target="">Supp</a>] <br>
      Lingran Zhao (Peking University)*; Zhen Dong (UC Berkeley); Kurt Keutzer (EECS, UC Berkeley)</li>

      <li><strong>"It‚Äôs a Match!" - A Benchmark of Task Affinity Scores for Joint Learning</strong>  [<a href="https://practical-dl.github.io/2023/long_paper/18/CameraReady/18.pdf" target="">Paper</a>]  [<a href="https://practical-dl.github.io/2023/long_paper/18/CameraReady/18-supp.zip" target="">Supp</a>]  <br>
      Raphael AZORIN (Huawei Technologies)*; Massimo Gallo (Huawei Technologies Co., Ltd.); alessandro finamore (huawei technologies); dario rossi (Huawei); Pietro Michiardi (EURECOM)</li>

      <li><strong>Simplifying Adversarial Attacks Against Object Detectors: a Fundamental Approach</strong> [<a href="https://practical-dl.github.io/2023/long_paper/21/CameraReady/21.pdf" target="">Paper</a>]  <br>
      Thomas Cilloni (University of Mississippi)*; Charles Fleming (Cisco Research); Charles Walter (University of Mississippi)</li>

      <li><strong>Deep Active Learning with Contrastive Learning Under Realistic Data Pool Assumptions</strong> [<a href="https://practical-dl.github.io/2023/long_paper/25/CameraReady/25.pdf" target="">Paper</a>] <br>
      Jihyo Kim (Seoul National University of Science and Technology); Jeonghyeon Kim (Seoul National University of Science and Technology); Sangheum Hwang (Seoul National University of Science and Technology)*</li>

      <li><strong>Towards Hardware-Specific Automatic Compression of Neural Networks</strong> [<a href="https://practical-dl.github.io/2023/long_paper/26/CameraReady/26.pdf" target="">Paper</a>] <br>
      Torben Krieger (Heidelberg University); Bernhard Klein (Heidelberg University)*; Holger Froening (University of Heidelberg)</li>

      <li><strong>A-ColViT : Real-time Interactive Colorization by Adaptive Vision Transformer</strong> [<a href="https://practical-dl.github.io/2023/long_paper/27/CameraReady/27.pdf" target="">Paper</a>] <br>
      Gwanghan Lee (Sungkyunkwan University (SKKU)  )*; Saebyeol Shin (Sungkyunkwan University (SKKU)); Donggeun Ko (Sungkyunkwan University); JiYeon Jung (SK telecom); Simon S Woo (Sungkyunkwan University (SKKU))</li>
      
    </ul> -->
    </div>
    </div>


    <div class="container">
    <h2>Accepted Extended Abstract</h2>
    <div class="overview">
    <!-- <ul>
      <li><strong>Output Sensitivity-Aware DETR Quantization</strong> [<a href="https://practical-dl.github.io/2023/extended_abstract/4/CameraReady/4.pdf" target="">Paper</a>] <br>
      Yafeng Huang (Nanjing University); Huanrui Yang (UC Berkeley)*; Zhen Dong (UC Berkeley); Denis A Gudovskiy (Panasonic); Tomoyuki Okuno (Panasonic); Yohei Nakata (Panasonic Corporation); Yuan Du (Nanjing University); Shanghang Zhang (Peking University); Kurt Keutzer (EECS, UC Berkeley)</li>

      <li><strong>Addressing distribution shift at test time in pre-trained language models</strong> [<a href="https://practical-dl.github.io/2023/extended_abstract/11/CameraReady/11.pdf" target="">Paper</a>] <br>
      Ayush Singh (EverNorth Healthcare Services)*; John Ortega (University of Santiago de Compostela)</li>

      <li><strong>QD-BEV: Quantization-aware View-guided Distillation for Multi-view 3D Object Detection</strong> [<a href="https://practical-dl.github.io/2023/extended_abstract/22/CameraReady/22.pdf" target="">Paper</a>] <br>
      yifan zhang (Nanjing University)*; Zhen Dong (UC Berkeley); Huanrui Yang (UC Berkeley); Ming Lu (Intel Labs China); Cheng-Ching Tseng (Peking University); Yandong Guo (OPPO Research Institute); Kurt Keutzer (EECS, UC Berkeley); LI DU (Nanjing University); Shanghang Zhang (Peking University)</li>

      <li><strong>Frequency Regularization for Improving Adversarial Robustness</strong> [<a href="https://practical-dl.github.io/2023/extended_abstract/24/CameraReady/24.pdf" target="">Paper</a>] <br>
      Binxiao Huang (The University of Hong Kong)*; Chaofan Tao (The University of Hong Kong); Rui Lin (The University of Hong Kong); Ngai Wong (The University of Hong Kong)</li>
    </ul> -->

    </div>
    </div>

  </div>
  </div>
    </div>
  </section>

    <!--==========================================
  =            Program Committee Section            =
  ===========================================-->
  
   <section class="popular-deals section bg-gray"> 
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="committee">Organizing Committee</h2>
          </div>
      <!-- <div class="left">
       <ul style="margin-left: 80px">
          <li>Yifu Ding, Beihang University</li>
          <li>Xiuying Wei, Beihang University</li>
          <li>Mingyuan Zhang, Nanyang Technological University</li>
          <li>Yiming Li, Tsinghua University</li>
          
        </ul>
    </div> -->
    <!-- <div class="right">
      <ul style="margin-right: 0px">
        <li>Renshuai Tao, Huawei Noah's Ark Lab</li>
        <li>Boying Wang, Institute of Software Chinese Academy of Sciences</li>
        <li>Yuhang Li, Yale University</li>
        <li>Zixiang Zhao, Xi‚Äôan Jiaotong University</li>
      </ul>
      </div> -->
        </div>
      </div>
    </div>
  </section>



  <section class="section"> 
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="committee">Technical Committee</h2>
          </div>
      <!-- <div class="left">
        <ul style="margin-left: 80px">
          <li>Linghui Zhu, Tsinghua University</li>
          <li>Yisong Xiao, Beihang University</li>
          <li>Yuxuan Wen, Beihang University</li>
          <li>Hang Yu, Beihang University</li>
          <li>Ruikui Wang, Beihang University</li>
          <li>Zixin Yin, Beihang University</li>
          <li>Jun Guo, Beihang University</li>
          <li>Simin Li, Beihang University</li>
          <li>Shunchang Liu, Beihang University</li>
          <li>Zonglei Jing, Beihang University</li>
          <li>Feng Zhu, University of Technology Sydney</li>
          <li>Kui Zhang, University of Science and Technology of China</li>
          <li>Zhipeng Wei, Fudan University</li>
      </ul>
    </div> -->

    <!-- <div class="right">
      <ul style="margin-right: 0px">
        <li>Tianlin Li, Nanyang Technological University</li>
        <li>Bangyan He, Institute of Information Engineering, Chinese Academy of Sciences</li>
        <li>Jingzhi Li, Institute of Information Engineering, Chinese Academy of Sciences</li>
        <li>Xiaojun Jia, Institute of Information Engineering, Chinese Academy of Sciences</li>
        <li>Bo Liu, National Space Science Center, Chinese Academy of Sciences</li>
        <li>Tianyuan Zhang, Beihang University</li>
        <li>Shihao Bai, Beihang University</li>
        <li>Xiaowei zhao, Beihang University</li>
        <li>Huangxinxin Xu, Wuhan University</li>
          <li>Maura Pintor, University of Cagliari</li>
          <li>Jiachen Sun, University of Michigan</li>
          <li>Yulong Cao, University of Michigan, Ann Arbor</li>
          <li>YiKun Xu, Institute of Information Engineering, Chinese Academy of Sciences</li>
          <li>Rajkumar Theagarajan, University of California, Riverside</li>
      </ul>
      </div> -->
        </div>
      </div>
    </div>
  </section>

<!--==========================================
=            Sponsors Section            =
===========================================-->

  <section class="section">
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="sponsors">Sponsors</h2>
        </div>
      <!-- <div class="row"> 
        <div class="section-title">
          <div class="col-3" align="center">
            <img src="./res/logo1.png" width="80%">
          </div>
          <div class="col-3" align="center">
            <img src="./res/logo2.png" width="80%">
          </div>
          <div class="col-3" align="center">
            <img src="./res/logo3.png" width="80%">
          </div>
          <div class="col-3" align="center">
            <img src="./res/logo4.png" width="80%">
          </div>
        -->
      </div>
      </div>
    </div>
  </section>




  <!--==========================================
=            Previous Workshops Section            =
===========================================-->

  <!-- <section class="popular-deals section bg-gray">
    <div class="container">
      <div class="row">
        <div class="col-12"> 
          <div class="section-title">
            <h2 id="previous">Previous Workshops</h2>
        </div>
        <p><a href="https://practical-dl.github.io/2022/index" style="color:blue;">1st International Workshop on Practical Deep Learning in the Wild</a> @ AAAI 2022</p>
      </div>
    </div>
  </section> -->
  
  <!--============================
  =            Footer            =
  =============================-->
  
  <!-- Footer Bottom -->
  <footer class="footer-bottom"> 
    <!-- Container Start -->
    <div class="container">
      <div class="row">
        <div class="col-sm-12 col-12"> 
          <!-- Copyright -->
          <div class="copyright">
            <p class="text-center">For any further questions, you can contact <a href="mailto:qinhaotong@buaa.edu.cn"><font color="#5672f9">Haotong Qin</font></a>, <a href="mailto:gongruihao@sensetime.com"><font color="#5672f9">Ruihao Gong</font></a>, and <a href="mailto:liuaishan@buaa.edu.cn"><font color="#5672f9">Aishan Liu</font></a>.</p>
            <!-- <p class="text-center">For any further questions, you can contact <a href="mailto:qinhaotong@buaa.edu.cn"><font color="#5672f9">Haotong Qin</font></a>, <a href="mailto:xinyun.chen@berkeley.edu"><font color="#5672f9">Xinyun Chen</font></a>, or <a href="mailto:yingwei.li@jhu.edu"><font color="#5672f9">Yingwei Li</font></a>.</p> -->
              <br class="clear">
          </div>
        </div>
      </div>
    </div>
  </footer>
  
  <!-- JAVASCRIPTS --> 
  <script src="./res/jquery.min.js"></script> 
  <script src="./res/jquery-ui.min.js"></script> 
  <script src="./res/tether.min.js"></script> 
  <script src="./res/jquery.raty-fa.js"></script> 
  <script src="./res/popper.min.js"></script> 
  <script src="./res/bootstrap.min.js"></script> 
  <script src="./res/bootstrap-slider.min.js"></script> 
  <script src="./res/slick.min.js"></script> 
  <script src="./res/jquery.nice-select.min.js"></script> 
  <script src="./res/jquery.fancybox.pack.js"></script> 
  <script src="./res/SmoothScroll.min.js"></script> 
  <script src="./res/scripts.js"></script>
  
  
  
</body></html>
